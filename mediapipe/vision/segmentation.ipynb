{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation\n",
    "\n",
    "https://developers.google.com/mediapipe/solutions/vision/image_segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -O ./models/deeplabv3.tflite -q https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/deeplabv3.tflite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FILENAMES = ['./../../../../test_img/f3978ebc-9030-49e7-aa5e-4a370a955e1b.jpg',\n",
    "                   './../../../../test_img/download.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseOptions = mp.tasks.BaseOptions\n",
    "ImageSegmenter = mp.tasks.vision.ImageSegmenter\n",
    "ImageSegmenterOptions = mp.tasks.vision.ImageSegmenterOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "\n",
    "options = ImageSegmenterOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.IMAGE,\n",
    "    output_category_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "\n",
    "def resize_and_show(image, file_name):\n",
    "    h, w = image.shape[:2]\n",
    "    if h < w:\n",
    "        img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n",
    "    else:\n",
    "        img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "    cv2.imshow(f'Segmentation mask of {file_name}:', img)\n",
    "    cv2.waitKey(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 1200)\n",
      "Segmentation mask of ./../../../../test_img/f3978ebc-9030-49e7-aa5e-4a370a955e1b.jpg:\n",
      "(189, 267)\n",
      "Segmentation mask of ./../../../../test_img/download.jpg:\n"
     ]
    }
   ],
   "source": [
    "# default\n",
    "BG_COLOR = (192, 192, 192) # gray\n",
    "MASK_COLOR = (255, 255, 255) # white\n",
    "\n",
    "with ImageSegmenter.create_from_options(options) as segmenter:\n",
    "    for file_name in IMAGE_FILENAMES:\n",
    "        mp_image = mp.Image.create_from_file(file_name)\n",
    "        segmented_masks = segmenter.segment(mp_image)\n",
    "        category_mask = segmented_masks.category_mask\n",
    "\n",
    "        image_data = mp_image.numpy_view()\n",
    "        fg_image = np.zeros(image_data.shape, dtype=np.uint8)\n",
    "        fg_image[:] = MASK_COLOR\n",
    "        bg_image = np.zeros(image_data.shape, dtype=np.uint8)\n",
    "        bg_image[:] = BG_COLOR\n",
    "\n",
    "        # 信頼度以上かどうかをboolで表す\n",
    "        condition = np.stack((category_mask.numpy_view(),) * 3, axis=-1) > 0.5\n",
    "        # true=fg_image, false=bg_image\n",
    "        output_image = np.where(condition, fg_image, bg_image)\n",
    "\n",
    "        print(f'Segmentation mask of {file_name}:')\n",
    "        resize_and_show(output_image, file_name)\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blurred background of ./../../../../test_img/f3978ebc-9030-49e7-aa5e-4a370a955e1b.jpg:\n",
      "Blurred background of ./../../../../test_img/download.jpg:\n"
     ]
    }
   ],
   "source": [
    "# application(対象以外をぼかす)\n",
    "\n",
    "with ImageSegmenter.create_from_options(options) as segmenter:\n",
    "    for file_name in IMAGE_FILENAMES:\n",
    "        mp_image = mp.Image.create_from_file(file_name)\n",
    "        segmented_masks = segmenter.segment(mp_image)\n",
    "        category_mask = segmented_masks.category_mask\n",
    "\n",
    "        # true\n",
    "        image_data = cv2.cvtColor(mp_image.numpy_view(), cv2.COLOR_BGR2RGB)\n",
    "        # false(background)\n",
    "        blurred_image = cv2.GaussianBlur(image_data, (55,55), 0)\n",
    "        # boolマスク作成\n",
    "        condition = np.stack((category_mask.numpy_view(),) * 3, axis=-1) > 0.1\n",
    "        output_image = np.where(condition, image_data, blurred_image)\n",
    "        \n",
    "        print(f'Blurred background of {file_name}:')\n",
    "        resize_and_show(output_image, file_name)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseOptions = mp.tasks.BaseOptions\n",
    "ImageSegmenter = mp.tasks.vision.ImageSegmenter\n",
    "ImageSegmenterOptions = mp.tasks.vision.ImageSegmenterOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "options = ImageSegmenterOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.VIDEO,\n",
    "    output_category_mask=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('./../../../../test_video/2795691-hd_1920_1080_25fps.mp4')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "output_vid = cv2.VideoWriter('./../segmentation_output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ImageSegmenter.create_from_options(options) as segmenter:\n",
    "    frame_index = 1\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            numpy_frame_from_opencv = np.asarray(frame)\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=numpy_frame_from_opencv)\n",
    "            frame_timestamp_ms = int(1000 * frame_index / fps)\n",
    "            segmented_masks = segmenter.segment_for_video(mp_image, frame_timestamp_ms)\n",
    "            category_mask = segmented_masks.category_mask\n",
    "            \n",
    "            # true\n",
    "            blurred_image = cv2.GaussianBlur(numpy_frame_from_opencv, (55,55), 0)\n",
    "            # boolマスク作成\n",
    "            condition = np.stack((category_mask.numpy_view(),) * 3, axis=-1) > 0.1\n",
    "            # 組み合わせ\n",
    "            output_image = np.where(condition, numpy_frame_from_opencv, blurred_image)\n",
    "            # 書き込み\n",
    "            output_vid.write(output_image)\n",
    "            frame_index += 1\n",
    "        else:\n",
    "            # VideoWriterを解放\n",
    "            output_vid.release()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## camera\n",
    "image推論を連続で使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseOptions = mp.tasks.BaseOptions\n",
    "ImageSegmenter = mp.tasks.vision.ImageSegmenter\n",
    "ImageSegmenterOptions = mp.tasks.vision.ImageSegmenterOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "# Create a image segmenter instance with the image mode:\n",
    "options = ImageSegmenterOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.IMAGE,\n",
    "    output_category_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ImageSegmenter.create_from_options(options) as segmenter:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            numpy_frame_from_opencv = np.asarray(frame)\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=numpy_frame_from_opencv)\n",
    "            segmented_masks = segmenter.segment(mp_image)\n",
    "            category_mask = segmented_masks.category_mask\n",
    "\n",
    "            # false(background)\n",
    "            blurred_image = cv2.GaussianBlur(numpy_frame_from_opencv, (55,55), 0)\n",
    "            # boolマスク作成\n",
    "            condition = np.stack((category_mask.numpy_view(),) * 3, axis=-1) > 0.1\n",
    "            output_image = np.where(condition, numpy_frame_from_opencv, blurred_image)\n",
    "\n",
    "            cv2.imshow('camera' , output_image)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
